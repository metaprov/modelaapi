// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.2.0
// - protoc             v3.19.1
// source: github.com/metaprov/modelaapi/services/batchpredictord/v1/batchpredictord.proto

package v1

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.32.0 or later.
const _ = grpc.SupportPackageIsVersion7

// BatchClient is the client API for Batch service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type BatchClient interface {
	// Ingest a new dataset to the store, the store creates a new layouts and set of keys
	// for the new dataset
	BatchPredict(ctx context.Context, in *BatchPredictRequest, opts ...grpc.CallOption) (*BatchPredictResponse, error)
	Shutdown(ctx context.Context, in *ShutdownRequest, opts ...grpc.CallOption) (*ShutdownResponse, error)
}

type batchClient struct {
	cc grpc.ClientConnInterface
}

func NewBatchClient(cc grpc.ClientConnInterface) BatchClient {
	return &batchClient{cc}
}

func (c *batchClient) BatchPredict(ctx context.Context, in *BatchPredictRequest, opts ...grpc.CallOption) (*BatchPredictResponse, error) {
	out := new(BatchPredictResponse)
	err := c.cc.Invoke(ctx, "/github.com.metaprov.modelaapi.services.batchpredictord.v1.Batch/BatchPredict", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *batchClient) Shutdown(ctx context.Context, in *ShutdownRequest, opts ...grpc.CallOption) (*ShutdownResponse, error) {
	out := new(ShutdownResponse)
	err := c.cc.Invoke(ctx, "/github.com.metaprov.modelaapi.services.batchpredictord.v1.Batch/Shutdown", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// BatchServer is the server API for Batch service.
// All implementations must embed UnimplementedBatchServer
// for forward compatibility
type BatchServer interface {
	// Ingest a new dataset to the store, the store creates a new layouts and set of keys
	// for the new dataset
	BatchPredict(context.Context, *BatchPredictRequest) (*BatchPredictResponse, error)
	Shutdown(context.Context, *ShutdownRequest) (*ShutdownResponse, error)
	mustEmbedUnimplementedBatchServer()
}

// UnimplementedBatchServer must be embedded to have forward compatible implementations.
type UnimplementedBatchServer struct {
}

func (UnimplementedBatchServer) BatchPredict(context.Context, *BatchPredictRequest) (*BatchPredictResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method BatchPredict not implemented")
}
func (UnimplementedBatchServer) Shutdown(context.Context, *ShutdownRequest) (*ShutdownResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Shutdown not implemented")
}
func (UnimplementedBatchServer) mustEmbedUnimplementedBatchServer() {}

// UnsafeBatchServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to BatchServer will
// result in compilation errors.
type UnsafeBatchServer interface {
	mustEmbedUnimplementedBatchServer()
}

func RegisterBatchServer(s grpc.ServiceRegistrar, srv BatchServer) {
	s.RegisterService(&Batch_ServiceDesc, srv)
}

func _Batch_BatchPredict_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(BatchPredictRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(BatchServer).BatchPredict(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/github.com.metaprov.modelaapi.services.batchpredictord.v1.Batch/BatchPredict",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(BatchServer).BatchPredict(ctx, req.(*BatchPredictRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Batch_Shutdown_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ShutdownRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(BatchServer).Shutdown(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/github.com.metaprov.modelaapi.services.batchpredictord.v1.Batch/Shutdown",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(BatchServer).Shutdown(ctx, req.(*ShutdownRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// Batch_ServiceDesc is the grpc.ServiceDesc for Batch service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var Batch_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "github.com.metaprov.modelaapi.services.batchpredictord.v1.Batch",
	HandlerType: (*BatchServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "BatchPredict",
			Handler:    _Batch_BatchPredict_Handler,
		},
		{
			MethodName: "Shutdown",
			Handler:    _Batch_Shutdown_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "github.com/metaprov/modelaapi/services/batchpredictord/v1/batchpredictord.proto",
}
