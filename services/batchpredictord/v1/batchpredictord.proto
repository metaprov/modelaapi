syntax = "proto3";
option go_package = "github.com/metaprov/modelaapi/services/batchpredictord/v1";
package github.com.metaprov.modelaapi.services.batchpredictord.v1;

import "github.com/metaprov/modelaapi/pkg/apis/infra/v1alpha1/generated.proto";
import "github.com/metaprov/modelaapi/pkg/apis/inference/v1alpha1/generated.proto";
import "google/protobuf/empty.proto";


// A request to batch predictor
message BatchPredictRequest {
    github.com.metaprov.modelaapi.pkg.apis.inference.v1alpha1.Prediction prediction     = 1;
    github.com.metaprov.modelaapi.pkg.apis.infra.v1alpha1.VirtualBucket  bucket     = 2;
    github.com.metaprov.modelaapi.pkg.apis.infra.v1alpha1.Connection     connection = 3;
    map<string,bytes>                                                    secret     = 4;
}

message BatchPredictResponse {
    int32 rows = 1; // number of predicted rows
}

message ShutdownRequest {}
message ShutdownResponse{}




service Batch {
    // Ingest a new dataset to the store, the store creates a new layouts and set of keys
    // for the new dataset
    rpc BatchPredict(BatchPredictRequest) returns (BatchPredictResponse) {}
    rpc Shutdown(ShutdownRequest) returns (ShutdownResponse) {}
}