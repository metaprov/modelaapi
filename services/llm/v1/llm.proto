syntax = "proto3";
option go_package = "github.com/metaprov/modelaapi/services/llm/v1";
package github.com.metaprov.modelaapi.services.llm.v1;


import "google/protobuf/field_mask.proto";
import "google/api/annotations.proto";
import "github.com/metaprov/modelaapi/pkg/apis/genai/v1alpha1/generated.proto";


message ListLLMsRequest {
  string namespace = 1;
  map<string, string> labels = 2;
}

message ListLLMsResponse {
  github.com.metaprov.modelaapi.pkg.apis.genai.v1alpha1.LLMList llms = 1;
  string next_page_token = 2;
}


message CreateLLMRequest {
  github.com.metaprov.modelaapi.pkg.apis.genai.v1alpha1.LLM llm = 1;
}

message CreateLLMResponse {}


message UpdateLLMRequest {
  github.com.metaprov.modelaapi.pkg.apis.genai.v1alpha1.LLM llm = 1;
  google.protobuf.FieldMask field_mask = 2;
}

message UpdateLLMResponse {}


message GetLLMRequest {
  string namespace = 1;
  string name      = 2;

}

message GetLLMResponse {
  github.com.metaprov.modelaapi.pkg.apis.genai.v1alpha1.LLM llm = 1;
  string yaml = 2;

}

message DeleteLLMRequest {
  string namespace = 1;
  string name      = 2;
}

message DeleteLLMResponse {}


service LLMService {
  rpc ListLLMs(ListLLMsRequest) returns (ListLLMsResponse) {
    option (google.api.http).get = "/v1/llms/{namespace}";
  }

  rpc CreateLLM(CreateLLMRequest) returns (CreateLLMResponse) {
    option (google.api.http) = {
      post: "/v1/llms"
      body: "*"
    };
  }

  rpc GetLLM(GetLLMRequest) returns (GetLLMResponse) {
    option (google.api.http).get = "/v1/llms/{namespace}/{name}";
  }

  rpc UpdateLLM(UpdateLLMRequest) returns (UpdateLLMResponse) {
    option (google.api.http) = {
      put: "/v1/llms/{llm.metadata.namespace}/{llm.metadata.name}"
      body: "*"
    };
  }

  rpc DeleteLLM(DeleteLLMRequest) returns (DeleteLLMResponse) {
    option (google.api.http).delete = "/v1/llms/{namespace}/{name}";
  }
}