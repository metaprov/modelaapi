
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.5.0
  creationTimestamp: null
  name: datapipelines.data.modeld.io
spec:
  group: data.modeld.io
  names:
    categories:
    - data
    - modeld
    kind: DataPipeline
    listKind: DataPipelineList
    plural: datapipelines
    shortNames:
    - dp
    singular: datapipeline
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - jsonPath: .status.conditions[?(@.type=="Ready")].status
      name: Ready
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1alpha1
    schema:
      openAPIV3Schema:
        description: DataPipeline represents the ETL flow from the data sources to
          a processed dataset, ready for training.
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: DataPipelineSpec defines the desired state of a DataPipeline
            properties:
              datasetSelector:
                additionalProperties:
                  type: string
                description: DatasetSelector is used to select datasets for processing
                  in the pipeline
                type: object
              defaultCompilerSpec:
                description: This is the default compiler spec
                properties:
                  compiler:
                    description: Set one or more targets
                    type: string
                  enable:
                    description: Enable set the enable to
                    type: boolean
                  targets:
                    description: Set one or more targets for the compiler
                    items:
                      type: string
                    type: array
                type: object
              description:
                description: Description of the data pipeline
                type: string
              observedGeneration:
                description: ObservedGeneration is the Last generation that was acted
                  on
                format: int64
                type: integer
              output:
                description: The output definition
                properties:
                  action:
                    default: create
                    description: Action define how the new data will be created
                    type: string
                  datasetName:
                    default: ""
                    description: DatasetName is the name of the dataset that will
                      be created. if nil, the system will not create the dataset.
                    type: string
                  format:
                    default: csv
                    description: Format is the format of the output data
                    enum:
                    - csv
                    - json
                    - parquet
                    - tde
                    - sql
                    - table
                    - fwf
                    - excel
                    - sas
                    - spss
                    - auto
                    type: string
                  location:
                    description: Location of the generated data
                    properties:
                      bucketName:
                        type: string
                      path:
                        description: Path to the full data file (e.g. csv file).
                        type: string
                    required:
                    - bucketName
                    - path
                    type: object
                type: object
              owner:
                default: no-one
                description: Owner of this data pipeline
                pattern: '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'
                type: string
              recipeOrder:
                description: RecipeOrder defines the list of recipes and the order
                  they need to run
                items:
                  properties:
                    Dependents:
                      description: Dependents is the list of recipe that need to run
                        after this recipe.
                      items:
                        type: string
                      type: array
                    recipeName:
                      description: RecipeName is the name of the recipe to run
                      type: string
                  type: object
                type: array
              schedule:
                description: Schedule is a cron field to schedule the data pipeline.
                properties:
                  cron:
                    description: Cron string of the schedule.
                    type: string
                  endDay:
                    description: EndDay is the end day of the schedule
                    format: date-time
                    type: string
                  endTime:
                    description: EndTime is the end time of the schedule
                    properties:
                      nanos:
                        description: Non-negative fractions of a second at nanosecond
                          resolution. Negative second values with fractions must still
                          have non-negative nanos values that count forward in time.
                          Must be from 0 to 999,999,999 inclusive. This field may
                          be limited in precision depending on context.
                        format: int32
                        type: integer
                      seconds:
                        description: Represents seconds of UTC time since Unix epoch
                          1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z
                          to 9999-12-31T23:59:59Z inclusive.
                        format: int64
                        type: integer
                    required:
                    - nanos
                    - seconds
                    type: object
                  startDay:
                    description: StartDay is the start day of the schedule
                    format: date-time
                    type: string
                  startTime:
                    description: The start time of the schedule
                    format: date-time
                    type: string
                  type:
                    description: The type of schedule events.
                    enum:
                    - now
                    - once
                    - hourly
                    - daily
                    - weekly
                    - monthly
                    - yearly
                    - cron
                    type: string
                type: object
              versionName:
                description: VersionName is the data product version of the data pipeline
                type: string
              workloadClassName:
                default: default-workload-class
                description: WorkloadClassName is the name of the workload class used
                  to run this pipeline. This is assigned by the datapipeline
                type: string
            type: object
          status:
            description: DataPipelineStatus is the observed state of the DataPipeline
              object.
            properties:
              conditions:
                items:
                  description: DataPipelineCondition describes the state of a wrangler
                    at a certain point.
                  properties:
                    lastTransitionTime:
                      description: Last time the condition transitioned from one status
                        to another.
                      format: date-time
                      type: string
                    message:
                      description: A human readable message indicating details about
                        the transition.
                      type: string
                    reason:
                      description: The reason for the condition's last transition.
                      type: string
                    status:
                      description: Status of the condition, one of True, False, Unknown.
                      type: string
                    type:
                      description: Type of account condition.
                      type: string
                  required:
                  - status
                  - type
                  type: object
                type: array
            type: object
        required:
        - metadata
        - spec
        type: object
    served: true
    storage: true
    subresources:
      status: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
