package v1alpha1

import (
	catalog "github.com/metaprov/modelaapi/pkg/apis/catalog/v1alpha1"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

type (
	APIFormat string
)

const (
	OpenAIAPIFormat APIFormat = "openai"
)

// +kubebuilder:subresource:status
// +kubebuilder:resource:path=llms,singular=llm,shortName=llm,categories={llm,modela}
// +kubebuilder:object:root=true
// +kubebuilder:storageversion
// +kubebuilder:printcolumn:name="Owner",type="string",JSONPath=".spec.owner",priority=1
// +kubebuilder:printcolumn:name="Last Sync",type="date",JSONPath=".status.lastSyncAt",description=""
// +kubebuilder:printcolumn:name="Age",type="date",JSONPath=".metadata.creationTimestamp"
// LLM represents a deployment of one or more large language models augmented by Knowledge Bases
type LLM struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty" protobuf:"bytes,1,opt,name=metadata"`
	Spec              LLMSpec   `json:"spec,omitempty" protobuf:"bytes,2,opt,name=spec"`
	Status            LLMStatus `json:"status,omitempty" protobuf:"bytes,3,opt,name=status"`
}

// +kubebuilder:object:root=true
// LLMList contains a list of LLMs
type LLMList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty" protobuf:"bytes,1,opt,name=metadata"`
	Items           []KnowledgeBase `json:"items" protobuf:"bytes,2,rep,name=items"`
}

type LLMAccessSpec struct {
	// The port number that will be exposed by the Kubernetes Service to serve completion requests.
	// +kubebuilder:validation:Optional
	// +kubebuilder:validation:Minimum=1024
	// +kubebuilder:validation:Maximum=65535
	// +kubebuilder:validation:Optional
	// +kubebuilder:default:=8080
	Port *int32 `json:"port,omitempty" protobuf:"varint,1,opt,name=port"`
	// The port number that will be exposed on the external address of every node on the cluster, in the case of the
	// AccessType being equal to NodePort. Traffic from the port will be forwarded to the LLM proxy deployment
	// +kubebuilder:validation:Minimum=0
	// +kubebuilder:validation:Maximum=65535
	// +kubebuilder:validation:Optional
	NodePort *int32 `json:"nodePort,omitempty" protobuf:"varint,2,opt,name=nodePort"`
	// The Kubernetes-native access method which specifies how the Kubernetes Service created by the Predictor will be exposed.
	// See https://modela.ai/docs/docs/serving/production/#access-method for a detailed description of each access type
	// +kubebuilder:default:="cluster-ip"
	// +kubebuilder:validation:Optional
	AccessType catalog.AccessType `json:"accessType,omitempty" protobuf:"bytes,4,opt,name=accessType"`
}

// LLMSpec specifies the configuration of the LLM proxy
type LLMSpec struct {
	// Owner specifies the name of the Account which the object belongs to
	// +kubebuilder:default:="no-one"
	// +kubebuilder:validation:Optional
	Owner *string `json:"owner,omitempty" protobuf:"bytes,1,opt,name=owner"`
	// The user-provided description of the LLM
	// +kubebuilder:default:=""
	// +kubebuilder:validation:MaxLength=512
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" protobuf:"bytes,2,opt,name=description"`
	// The name of the Serving Site under which the LLM proxy deployment will be created.
	// If empty, default to the Data Product's default Serving Site
	// +kubebuilder:validation:Optional
	ServingSiteName *string `json:"servingSiteName,omitempty" protobuf:"bytes,3,opt,name=servingSiteName"`
	// The resource requirements that will be allocated to the proxy deployment
	// +kubebuilder:validation:Optional
	Resources catalog.ResourceSpec `json:"resources,omitempty" protobuf:"bytes,4,opt,name=resources"`
	// The large language models served by the proxy
	Models []ModelServingSpec `json:"models,omitempty" protobuf:"bytes,5,opt,name=models"`
	// The configuration for Alerts generated by the proxy
	// +kubebuilder:validation:Optional
	Notification *catalog.NotificationSpec `json:"notification,omitempty" protobuf:"bytes,6,opt,name=notification"`
}

// ModelServingSpec specifies the serving configuration for a single LLM endpoint
type ModelServingSpec struct {
	// The unique name of the model
	// +kubebuilder:validation:Required
	// +required
	Name string `json:"name,omitempty" protobuf:"bytes,1,opt,name=name"`
	// The query engine used to augment requests to the LLM.
	// If unspecified, no augmentation will be performed
	QueryEngine *QueryEngineSpec `json:"queryEngine,omitempty" protobuf:"bytes,2,opt,name=queryEngine"`
	// The path suffix where the model will be served.
	// If unspecified, the default suffix for the LLM provider will be used
	Path *string `json:"path,omitempty" protobuf:"bytes,3,opt,name=path"`
	// The collection of path suffixes where the model will be served
	Paths []string `json:"paths,omitempty" protobuf:"bytes,4,opt,name=paths"`
	// The API format standard that will be served for the model.
	// If unspecified, default to the OpenAI API format
	Format *APIFormat `json:"format,omitempty" protobuf:"bytes,5,opt,name=format"`
	// The default LLM to use for all internal and consumer-facing completion requests
	Model ModelSpec `json:"model,omitempty" protobuf:"bytes,6,opt,name=model"`
}

// ModelMetrics contains the metrics for a single model (collected by Prometheus)
type ModelMetrics struct {
	// 50% latency for predictions served by the model
	// +kubebuilder:validation:Optional
	P50 float64 `json:"p50,omitempty" protobuf:"bytes,4,opt,name=p50"`
	// 95% latency for predictions served by the model
	// +kubebuilder:validation:Optional
	P95 float64 `json:"p95,omitempty" protobuf:"bytes,5,opt,name=p95"`
	// 99% latency for predictions served by the model
	// +kubebuilder:validation:Optional
	P99 float64 `json:"p99,omitempty" protobuf:"bytes,6,opt,name=p99"`
	// The total number of predictions served by the model
	TotalPredictions int32 `json:"totalPredictions,omitempty" protobuf:"varint,8,opt,name=totalPredictions"`
}

// ModelStatus describes the current state of a single model served by the LLM proxy
type ModelStatus struct {
	// The unique name of the model
	// +kubebuilder:validation:Required
	// +required
	Name string `json:"name,omitempty" protobuf:"bytes,1,opt,name=name"`
	// The reference to the Kubernetes Deployment that manages the pods for the prediction proxy
	// +kubebuilder:validation:Optional
	DeploymentRef *v1.ObjectReference `json:"deploymentRef,omitempty" protobuf:"bytes,2,opt,name=deploymentRef"`
	// The reference to the Kubernetes Service which exposes the prediction proxy externally
	// +kubebuilder:validation:Optional
	ServiceRef *v1.ObjectReference `json:"serviceRef,omitempty" protobuf:"bytes,3,opt,name=serviceRef"`
	// The details of the last failure that occurred while deploying the model
	// +kubebuilder:validation:Optional
	FailureMessage *string `json:"failureMessage,omitempty" protobuf:"bytes,4,opt,name=failureMessage"`
	// Metrics for the model, applicable if Prometheus is enabled on the cluster
	Metrics *ModelMetrics `json:"modelMetrics,omitempty" protobuf:"bytes,5,opt,name=modelMetrics"`
}

type LLMStatus struct {
	// ObservedGeneration specifies the last generation that was reconciled
	//+kubebuilder:validation:Optional
	ObservedGeneration int64 `json:"observedGeneration,omitempty" protobuf:"varint,1,opt,name=observedGeneration"`
	// Models contains the collection of statuses for each model served by the LLM
	Models []ModelStatus `json:"documents,omitempty" protobuf:"bytes,2,opt,name=documents"`
	// Endpoint contains the URL where the LLM proxy service is exposed
	Endpoint *string `json:"endpoint,omitempty" protobuf:"bytes,3,opt,name=endpoint"`
	// DeployedAt specifies the time that the LLM proxy deployment was created
	//+kubebuilder:validation:Optional
	DeployedAt *metav1.Time `json:"deployedAt,omitempty" protobuf:"bytes,4,opt,name=deployedAt"`
	// The last time the object was updated
	//+kubebuilder:validation:Optional
	UpdatedAt *metav1.Time `json:"updatedAt,omitempty" protobuf:"bytes,6,opt,name=updatedAt"`
	// +kubebuilder:validation:Optional
	// +patchMergeKey=type
	// +patchStrategy=merge
	Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,7,rep,name=conditions"`
}
