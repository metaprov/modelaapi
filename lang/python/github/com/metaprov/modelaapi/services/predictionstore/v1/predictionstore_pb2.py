# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: github.com/metaprov/modelaapi/services/predictionstore/v1/predictionstore.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from github.com.metaprov.modelaapi.pkg.apis.data.v1alpha1 import generated_pb2 as github_dot_com_dot_metaprov_dot_modelaapi_dot_pkg_dot_apis_dot_data_dot_v1alpha1_dot_generated__pb2
from github.com.metaprov.modelaapi.pkg.apis.infra.v1alpha1 import generated_pb2 as github_dot_com_dot_metaprov_dot_modelaapi_dot_pkg_dot_apis_dot_infra_dot_v1alpha1_dot_generated__pb2
from k8s.io.api.core.v1 import generated_pb2 as k8s_dot_io_dot_api_dot_core_dot_v1_dot_generated__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\nOgithub.com/metaprov/modelaapi/services/predictionstore/v1/predictionstore.proto\x12\x39github.com.metaprov.modelaapi.services.predictionstore.v1\x1a\x44github.com/metaprov/modelaapi/pkg/apis/data/v1alpha1/generated.proto\x1a\x45github.com/metaprov/modelaapi/pkg/apis/infra/v1alpha1/generated.proto\x1a\"k8s.io/api/core/v1/generated.proto\"\xfa\x01\n\x18PredictionsIngestRequest\x12N\n\x07\x64\x61taset\x18\x01 \x01(\x0b\x32=.github.com.metaprov.modelaapi.pkg.apis.data.v1alpha1.Dataset\x12\x0b\n\x03key\x18\x02 \x01(\t\x12U\n\nconnection\x18\x03 \x01(\x0b\x32\x41.github.com.metaprov.modelaapi.pkg.apis.infra.v1alpha1.Connection\x12*\n\x06secret\x18\x04 \x01(\x0b\x32\x1a.k8s.io.api.core.v1.Secret\"\x1a\n\x18PredictionIngestResponse2\xcf\x01\n\x16PredictionStoreService\x12\xb4\x01\n\x06Ingest\x12S.github.com.metaprov.modelaapi.services.predictionstore.v1.PredictionsIngestRequest\x1aS.github.com.metaprov.modelaapi.services.predictionstore.v1.PredictionIngestResponse\"\x00\x42;Z9github.com/metaprov/modelaapi/services/predictionstore/v1b\x06proto3')



_PREDICTIONSINGESTREQUEST = DESCRIPTOR.message_types_by_name['PredictionsIngestRequest']
_PREDICTIONINGESTRESPONSE = DESCRIPTOR.message_types_by_name['PredictionIngestResponse']
PredictionsIngestRequest = _reflection.GeneratedProtocolMessageType('PredictionsIngestRequest', (_message.Message,), {
  'DESCRIPTOR' : _PREDICTIONSINGESTREQUEST,
  '__module__' : 'github.com.metaprov.modelaapi.services.predictionstore.v1.predictionstore_pb2'
  # @@protoc_insertion_point(class_scope:github.com.metaprov.modelaapi.services.predictionstore.v1.PredictionsIngestRequest)
  })
_sym_db.RegisterMessage(PredictionsIngestRequest)

PredictionIngestResponse = _reflection.GeneratedProtocolMessageType('PredictionIngestResponse', (_message.Message,), {
  'DESCRIPTOR' : _PREDICTIONINGESTRESPONSE,
  '__module__' : 'github.com.metaprov.modelaapi.services.predictionstore.v1.predictionstore_pb2'
  # @@protoc_insertion_point(class_scope:github.com.metaprov.modelaapi.services.predictionstore.v1.PredictionIngestResponse)
  })
_sym_db.RegisterMessage(PredictionIngestResponse)

_PREDICTIONSTORESERVICE = DESCRIPTOR.services_by_name['PredictionStoreService']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'Z9github.com/metaprov/modelaapi/services/predictionstore/v1'
  _PREDICTIONSINGESTREQUEST._serialized_start=320
  _PREDICTIONSINGESTREQUEST._serialized_end=570
  _PREDICTIONINGESTRESPONSE._serialized_start=572
  _PREDICTIONINGESTRESPONSE._serialized_end=598
  _PREDICTIONSTORESERVICE._serialized_start=601
  _PREDICTIONSTORESERVICE._serialized_end=808
# @@protoc_insertion_point(module_scope)
